# üë®üèª‚Äçüíª LLM-Repo
This repository contains a curated list of awesome 150+ libs category wise.

<p align="center">
  <a href="https://www.linkedin.com/in/kalyanksnlp/">
    <img src="https://custom-icon-badges.demolab.com/badge/Kalyan%20KS-0A66C2?logo=linkedin-white&logoColor=fff" alt="LinkedIn">
  </a>
  <a href="https://x.com/kalyan_kpl">
    <img src="https://img.shields.io/badge/Kalyan%20KS-%23000000.svg?logo=X&logoColor=white" alt="Twitter">
  </a>
</p>

### Quick links
||||
|---|---|---|
| [LLM Training](#llm-training) | [LLM Fine-Tuning](#llm-fine-tuning) | [LLM Post-Training](#llm-post-training) |

## LLM Training 

| Library             | Description                                                                                     | Link |
|---------------------|-------------------------------------------------------------------------------------------------|------|
| PEFT                | State-of-the-art Parameter-Efficient Fine-Tuning library.                                       | Link |
| TRL                 | Train transformer language models with reinforcement learning.                                  | Link |
| unsloth            | Fine-tune LLMs faster with less memory.                                                          | Link |
| Transformers       | Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio. | Link |
| LLMBox             | A comprehensive library for implementing LLMs, including a unified training pipeline and comprehensive model evaluation. | Link |
| LitGPT             | Train and fine-tune LLM lightning fast.                                                          | Link |
| Mergoo            | A library for easily merging multiple LLM experts, and efficiently train the merged LLM.         | Link |

## LLM Fine-Tuning
| Library             | Description                                                                                     | Link |
|---------------------|-------------------------------------------------------------------------------------------------|------|
| Llama-Factory      | Easy and efficient LLM fine-tuning.                                                              | Link |
| Ludwig            | Low-code framework for building custom LLMs, neural networks, and other AI models.               | Link |
| Txtinstruct       | A framework for training instruction-tuned models.                                               | Link |
| Lamini            | An integrated LLM inference and tuning platform.                                                 | Link |

## LLM Post Training
| Library             | Description                                                                                     | Link |
|---------------------|-------------------------------------------------------------------------------------------------|------|
| XTuring           | xTuring provides fast, efficient and simple fine-tuning of open-source LLMs, such as Mistral, LLaMA, GPT-J, and more. | Link |
| RL4LMs            | A modular RL library to fine-tune language models to human preferences.                          | Link |
| DeepSpeed         | DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective. | Link |
| torchtune         | A PyTorch-native library specifically designed for fine-tuning LLMs.                             | Link |
| PyTorch Lightning | A library that offers a high-level interface for pretraining and fine-tuning LLMs.               | Link |
| Axolotl           | Tool designed to streamline post-training for various AI models.                                 | Link |



		



## ‚≠êÔ∏è Star History

[![Star History Chart](https://api.star-history.com/svg?repos=krishnlp007/LLM-Repo&type=Date)](https://star-history.com/#)

Please consider giving a star, if you find this repository useful. 
